{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f4a979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba90e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'epoch' : 10,\n",
    "    'batch_size' : 128,\n",
    "    'lr' : 0.01,\n",
    "    'device' : torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    'weight_path' : 'nps_for revisit.bin'\n",
    "     \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9039995c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('df_revisit.xlsx')\n",
    "df.columns = [str(i) for i in range(1,len(df.columns))] + ['target']\n",
    "for col in df.columns:\n",
    "    map_dict = dict(zip(df[col].unique(), range(0, df[col].nunique() )))\n",
    "    df[col] = df[col].map(map_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7f2fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "size_dict = defaultdict(dict)\n",
    "for col in df.columns:\n",
    "    size_dict[col]['size'] = df[col].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02c8d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NPSDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = dict()\n",
    "        for col in self.df.columns:\n",
    "            data[col] = torch.Tensor([self.df[col].iloc[idx]]).long().squeeze(-1)\n",
    "        \n",
    "        data['target'] = torch.Tensor([self.df['target'].iloc[idx]]).squeeze(-1)\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89567426",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Embedding \n",
    "class EmbeddingLayer(nn.Module):\n",
    "    def __init__(self, size_dict, embedding_dim):\n",
    "        super(EmbeddingLayer, self).__init__()\n",
    "        self.size_dict = size_dict\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding_layer = nn.ModuleDict()\n",
    "        \n",
    "        for col in size_dict.keys():\n",
    "            self.embedding_layer.update({col: nn.Embedding(self.size_dict[col]['size'], self.embedding_dim)})\n",
    "        \n",
    "  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        emb_l = []\n",
    "        for col in self.size_dict.keys():\n",
    "            inpu = x[col].long().view(-1,1)\n",
    "            emb_l.append(self.embedding_layer[col](inpu))\n",
    "        emb_final = torch.stack(emb_l, dim=1)\n",
    "        return emb_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37227011",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self,input_dim, droprate):\n",
    "        super(MLP, self).__init__()\n",
    "        dense_layers = []\n",
    "        dense_layers.append(nn.Linear(input_dim, 128))\n",
    "        dense_layers.append(nn.BatchNorm1d(128))\n",
    "        dense_layers.append(nn.ReLU())\n",
    "        dense_layers.append(nn.Dropout(droprate))\n",
    "        dense_layers.append(nn.Linear(128, 64))\n",
    "        dense_layers.append(nn.BatchNorm1d(64))\n",
    "        dense_layers.append(nn.ReLU())\n",
    "        dense_layers.append(nn.Dropout(droprate))\n",
    "        dense_layers.append(nn.Linear(64, 32))\n",
    "        dense_layers.append(nn.BatchNorm1d(32))\n",
    "        dense_layers.append(nn.ReLU())\n",
    "        dense_layers.append(nn.Dropout(droprate))\n",
    "        dense_layers.append(nn.Linear(32,1))\n",
    "        dense_layers.append(nn.Sigmoid())\n",
    "        self.dnn = nn.Sequential(*dense_layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.dnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3ee835",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myModel(nn.Module):\n",
    "    def __init__(self, size_dict, embedding_dim = 32, droprate = 0.1):\n",
    "        super(myModel, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.droprate = droprate\n",
    "        self.embedding_layer = EmbeddingLayer(size_dict, embedding_dim = embedding_dim)\n",
    "        self.input_dim = len(size_dict.keys()) *embedding_dim\n",
    "        \n",
    "        self.dnn = MLP(input_dim = self.input_dim, droprate = droprate)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        feature_embed = self.embedding_layer(x)\n",
    "        feature_embed = torch.flatten(feature_embed, start_dim=1)\n",
    "        y_pred = self.dnn(feature_embed)\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651a11e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, optimizer, device, metric_list = ['roc_auc_score','log_loss']):\n",
    "    model.train()\n",
    "    pred_list = []\n",
    "    label_list = []\n",
    "    pbar = tqdm(train_loader)\n",
    "    for data in pbar:\n",
    "        for i in data.keys():\n",
    "            data[i] = data[i].to(device)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        output = model(data)\n",
    "        label = data['target']\n",
    "        loss = criterion(output.squeeze(-1), label)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        pred_list.extend(output.squeeze(-1).cpu().detach().numpy())\n",
    "        label_list.extend(label.squeeze(-1).cpu().detach().numpy())\n",
    "        pbar.set_description(\"train Loss {}\".format(loss))\n",
    "    \n",
    "    loss_dict = {}\n",
    "    for metric in metric_list:\n",
    "        if metric == 'log_loss':\n",
    "            loss_dict[metric] = log_loss(label_list, pred_list)\n",
    "        else:\n",
    "            loss_dict[metric] = roc_auc_score(label_list, pred_list)\n",
    "    \n",
    "    return loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071c45eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_model(model, valid_loader, device, metric_list = ['roc_auc_score','log_loss']):\n",
    "    model.eval()\n",
    "    pred_list = []\n",
    "    label_list = []\n",
    "    pbar = tqdm(valid_loader)\n",
    "    for data in pbar:\n",
    "        for i in data.keys():\n",
    "            data[i] = data[i].to(device)\n",
    "    \n",
    "        output = model(data)\n",
    "        label = data['target']\n",
    "        loss = criterion(output.squeeze(-1), label)\n",
    "        \n",
    "        pred_list.extend(output.squeeze(-1).cpu().detach().numpy())\n",
    "        label_list.extend(label.squeeze(-1).cpu().detach().numpy())\n",
    "        pbar.set_description(\"valid Loss {}\".format(loss))\n",
    "        \n",
    "    loss_dict = {}\n",
    "    for metric in metric_list:\n",
    "        if metric == 'log_loss':\n",
    "            loss_dict[metric] = log_loss(label_list, pred_list)\n",
    "        else:\n",
    "            loss_dict[metric] = roc_auc_score(label_list, pred_list)\n",
    "    \n",
    "    return loss_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2871df",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = int(len(df) * 0.8)\n",
    "valid_df = df[:split].reset_index(drop=True)\n",
    "train_df = df[split:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69d5dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NPSDataset(train_df)\n",
    "valid_dataset = NPSDataset(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265e6587",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size = config['batch_size'], shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size = config['batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7a697f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = myModel(size_dict = size_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad857c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_device(gpu):\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(f'cuda:{gpu}')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    \n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59041a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = EmbeddingLayer(size_dict, embedding_dim = 32)\n",
    "l1 = nn.Linear(160,128)\n",
    "l2 = nn.Linear(128,64)\n",
    "for i in train_loader:\n",
    "    feature_embed = embedding_layer(i)\n",
    "    print(feature_embed.shape)\n",
    "    feature_embed = torch.flatten(feature_embed, start_dim=1)\n",
    "    print(feature_embed.shape)\n",
    "    output = l1(feature_embed)\n",
    "    print(output.shape)\n",
    "    output = l2(output)\n",
    "    print(output.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9fc7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = set_device(config['device'])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'], weight_decay = 0.001)\n",
    "criterion = criterion = nn.BCELoss()\n",
    "\n",
    "best_valid_loss = 100\n",
    "\n",
    "for i in range(config['epoch']):\n",
    "    train_metric = train_model(model, train_loader, optimizer = optimizer, device = device)\n",
    "    \n",
    "    valid_metric = valid_model(model, valid_loader, device = device)\n",
    "    \n",
    "    valid_loss = valid_metric['log_loss']\n",
    "    if valid_loss < best_valid_loss:\n",
    "        torch.save(model.state_dict(), config['weight_path'])\n",
    "        best_valid_loss = valid_loss\n",
    "        print('model_saved', valid_loss)\n",
    "    \n",
    "    print(f'train metric {train_metric}')\n",
    "    print(f'valid metric {valid_metric}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
